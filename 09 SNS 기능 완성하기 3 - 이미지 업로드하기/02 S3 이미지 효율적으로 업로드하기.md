# S3 이미지 효율적으로 업로드하기

## 1. 이미지 최적화 전략

이미지를 S3에 업로드할 때 효율성을 높이기 위한 여러 전략을 적용할 수 있습니다. 먼저 이미지 자체를 최적화하는 방법부터 살펴보겠습니다.



### 이미지 압축 및 리사이징

이미지 크기를 줄이는 것은 스토리지 비용 절감과 로딩 속도 향상에 직접적인 영향을 미칩니다. 업로드 전에 이미지를 적절한 크기로 리사이징하고 압축하는 작업을 수행합니다.

```java
@Service
@RequiredArgsConstructor
@Slf4j
public class ImageOptimizer {
    
    /**
     * 이미지 최적화
     * @param file 최적화할 이미지 파일
     * @return 최적화된 이미지 파일
     * @throws IOException 파일 처리 중 오류 발생 시
     */
    public MultipartFile optimizeImage(MultipartFile file) throws IOException {
        // 이미지 리사이징
        BufferedImage originalImage = ImageIO.read(file.getInputStream());
        BufferedImage resizedImage = resizeImage(originalImage, 800, 800);
        
        // 이미지 포맷 변환 및 압축
        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
        Iterator<ImageWriter> writers = ImageIO.getImageWritersByFormatName("jpeg");
        ImageWriter writer = writers.next();
        ImageWriteParam param = writer.getDefaultWriteParam();
        param.setCompressionMode(ImageWriteParam.MODE_EXPLICIT);
        param.setCompressionQuality(0.7f); // 70% 품질로 압축
        
        ImageOutputStream ios = ImageIO.createImageOutputStream(outputStream);
        writer.setOutput(ios);
        writer.write(null, new IIOImage(resizedImage, null, null), param);
        writer.dispose();
        ios.close();
        
        // MultipartFile로 변환
        return new MockMultipartFile(
            file.getName(),
            file.getOriginalFilename(),
            "image/jpeg",
            outputStream.toByteArray()
        );
    }
    
    /**
     * 이미지 리사이징
     * @param originalImage 원본 이미지
     * @param targetWidth 목표 너비
     * @param targetHeight 목표 높이
     * @return 리사이징된 이미지
     */
    private BufferedImage resizeImage(BufferedImage originalImage, int targetWidth, int targetHeight) {
        double originalWidth = originalImage.getWidth();
        double originalHeight = originalImage.getHeight();
        
        double scale = Math.min(targetWidth / originalWidth, targetHeight / originalHeight);
        
        int scaledWidth = (int) (originalWidth * scale);
        int scaledHeight = (int) (originalHeight * scale);
        
        BufferedImage resizedImage = new BufferedImage(scaledWidth, scaledHeight, BufferedImage.TYPE_INT_RGB);
        Graphics2D graphics2D = resizedImage.createGraphics();
        graphics2D.setRenderingHint(RenderingHints.KEY_INTERPOLATION, RenderingHints.VALUE_INTERPOLATION_BILINEAR);
        graphics2D.drawImage(originalImage, 0, 0, scaledWidth, scaledHeight, null);
        graphics2D.dispose();
        
        return resizedImage;
    }
}
```



### 이미지 포맷 최적화

이미지 포맷에 따라 파일 크기와 품질이 달라집니다. 웹 이미지의 경우 WebP나 AVIF와 같은 최신 포맷을 사용하면 더 작은 파일 크기로 더 나은 품질을 제공할 수 있습니다.

```java
@Service
@RequiredArgsConstructor
@Slf4j
public class ImageFormatConverter {
    
    /**
     * 이미지 포맷 변환
     * @param file 변환할 이미지 파일
     * @param format 변환할 포맷 (webp, avif 등)
     * @return 변환된 이미지 파일
     * @throws IOException 파일 처리 중 오류 발생 시
     */
    public MultipartFile convertFormat(MultipartFile file, String format) throws IOException {
        BufferedImage originalImage = ImageIO.read(file.getInputStream());
        
        ByteArrayOutputStream outputStream = new ByteArrayOutputStream();
        
        // WebP 변환 (WebP 라이브러리 필요)
        if ("webp".equalsIgnoreCase(format)) {
            // WebP 변환 로직
            // com.luciad.ria.util.image.WebPEncoder 사용 예시
            // WebPEncoder.write(originalImage, outputStream, 0.7f);
        } else {
            // 기본 JPEG 변환
            ImageIO.write(originalImage, "jpeg", outputStream);
        }
        
        return new MockMultipartFile(
            file.getName(),
            file.getOriginalFilename().substring(0, file.getOriginalFilename().lastIndexOf(".")) + "." + format,
            "image/" + format,
            outputStream.toByteArray()
        );
    }
}
```



## 2. S3 업로드 최적화



### 멀티파트 업로드 활용

대용량 파일을 업로드할 때는 S3의 멀티파트 업로드 기능을 활용하면 효율적입니다. 파일을 여러 부분으로 나누어 병렬로 업로드하고, 업로드가 완료된 후에 모든 부분을 결합합니다.

```java
@Service
@RequiredArgsConstructor
@Slf4j
public class S3MultipartUploadService {
    
    private final AmazonS3 amazonS3;
    
    @Value("${cloud.aws.s3.bucket}")
    private String bucket;
    
    /**
     * 멀티파트 업로드
     * @param file 업로드할 파일
     * @param directory 저장할 디렉토리
     * @return 업로드된 파일의 URL
     * @throws IOException 파일 처리 중 오류 발생 시
     */
    public String multipartUpload(MultipartFile file, String directory) throws IOException {
        // 파일명 생성
        String fileName = generateFileName(file.getOriginalFilename());
        String key = directory + "/" + fileName;
        
        // 멀티파트 업로드 초기화
        InitiateMultipartUploadRequest initRequest = new InitiateMultipartUploadRequest(bucket, key);
        InitiateMultipartUploadResult initResponse = amazonS3.initiateMultipartUpload(initRequest);
        String uploadId = initResponse.getUploadId();
        
        // 파일을 여러 부분으로 나누기
        long contentLength = file.getSize();
        long partSize = 5 * 1024 * 1024; // 5MB
        long filePosition = 0;
        List<PartETag> partETags = new ArrayList<>();
        
        try {
            for (int i = 1; filePosition < contentLength; i++) {
                partSize = Math.min(partSize, contentLength - filePosition);
                
                // 부분 업로드 요청 생성
                UploadPartRequest uploadRequest = new UploadPartRequest()
                    .withBucketName(bucket)
                    .withKey(key)
                    .withUploadId(uploadId)
                    .withInputStream(file.getInputStream())
                    .withPartSize(partSize)
                    .withPartNumber(i);
                
                // 부분 업로드 실행
                UploadPartResult uploadResult = amazonS3.uploadPart(uploadRequest);
                partETags.add(uploadResult.getPartETag());
                
                filePosition += partSize;
            }
            
            // 멀티파트 업로드 완료
            CompleteMultipartUploadRequest compRequest = new CompleteMultipartUploadRequest(
                bucket, key, uploadId, partETags);
            amazonS3.completeMultipartUpload(compRequest);
            
            // 업로드된 파일의 URL 반환
            return amazonS3.getUrl(bucket, key).toString();
            
        } catch (Exception e) {
            // 오류 발생 시 멀티파트 업로드 중단
            amazonS3.abortMultipartUpload(new AbortMultipartUploadRequest(bucket, key, uploadId));
            throw new IOException("멀티파트 업로드 중 오류 발생: " + e.getMessage());
        }
    }
    
    /**
     * 파일명 생성
     * @param originalFilename 원본 파일명
     * @return 생성된 파일명
     */
    private String generateFileName(String originalFilename) {
        String extension = originalFilename.substring(originalFilename.lastIndexOf("."));
        return UUID.randomUUID().toString() + extension;
    }
}
```



### 비동기 업로드 처리

이미지 업로드는 시간이 걸리는 작업이므로 비동기로 처리하면 사용자 경험을 향상시킬 수 있습니다. Spring의 `@Async` 어노테이션을 활용하여 비동기 처리를 구현합니다.

```java
@Service
@RequiredArgsConstructor
@Slf4j
public class AsyncImageUploadService {
    
    private final S3Service s3Service;
    private final ImageOptimizer imageOptimizer;
    private final MemberRepository memberRepository;
    
    /**
     * 비동기 이미지 업로드
     * @param file 업로드할 이미지 파일
     * @param memberId 사용자 ID
     * @return 업로드 작업 ID
     */
    public String uploadImageAsync(MultipartFile file, Long memberId) {
        String uploadId = UUID.randomUUID().toString();
        
        // 업로드 작업을 비동기로 실행
        CompletableFuture.runAsync(() -> {
            try {
                // 이미지 최적화
                MultipartFile optimizedFile = imageOptimizer.optimizeImage(file);
                
                // S3에 업로드
                String imageUrl = s3Service.uploadFile(optimizedFile, "profiles");
                
                // 사용자 정보 업데이트
                Member member = memberRepository.findById(memberId)
                    .orElseThrow(() -> new IllegalArgumentException("사용자를 찾을 수 없습니다."));
                
                member.updateProfileImage(imageUrl, imageUrl);
                memberRepository.save(member);
                
                log.info("이미지 업로드 완료: {}", imageUrl);
            } catch (Exception e) {
                log.error("이미지 업로드 중 오류 발생: {}", e.getMessage());
            }
        });
        
        return uploadId;
    }
}
```



## 3. 캐싱 및 CDN 활용



### CloudFront CDN 설정

이미지 로딩 속도를 향상시키기 위해 CloudFront와 같은 CDN을 활용합니다. CDN은 전 세계 여러 지역에 이미지를 캐싱하여 사용자에게 더 빠르게 제공합니다.

```java
@Service
@RequiredArgsConstructor
public class CloudFrontService {
    
    @Value("${cloud.aws.cloudfront.domain}")
    private String cloudFrontDomain;
    
    /**
     * CloudFront URL 생성
     * @param s3Key S3 객체 키
     * @return CloudFront URL
     */
    public String getCloudFrontUrl(String s3Key) {
        return "https://" + cloudFrontDomain + "/" + s3Key;
    }
    
    /**
     * CloudFront URL에서 S3 키 추출
     * @param cloudFrontUrl CloudFront URL
     * @return S3 객체 키
     */
    public String getS3KeyFromCloudFrontUrl(String cloudFrontUrl) {
        return cloudFrontUrl.substring(cloudFrontUrl.indexOf(cloudFrontDomain) + cloudFrontDomain.length() + 1);
    }
}
```



### 브라우저 캐싱 활용

이미지에 적절한 캐시 헤더를 설정하여 브라우저 캐싱을 활용합니다. 이렇게 하면 사용자가 같은 이미지를 다시 요청할 때 서버에 요청하지 않고 브라우저 캐시에서 가져올 수 있습니다.

```java
@Service
@RequiredArgsConstructor
public class S3Service {
    
    // 기존 코드...
    
    /**
     * 파일 업로드 (캐시 헤더 설정)
     * @param file 업로드할 파일
     * @param directory 저장할 디렉토리
     * @return 업로드된 파일의 URL
     * @throws IOException 파일 처리 중 오류 발생 시
     */
    public String uploadFileWithCache(MultipartFile file, String directory) throws IOException {
        // 파일명 생성
        String fileName = generateFileName(file.getOriginalFilename());
        
        // S3에 업로드할 객체 생성
        ObjectMetadata metadata = new ObjectMetadata();
        metadata.setContentType(file.getContentType());
        metadata.setContentLength(file.getSize());
        
        // 캐시 헤더 설정
        metadata.setCacheControl("public, max-age=31536000"); // 1년
        metadata.setExpirationDate(new Date(System.currentTimeMillis() + 31536000L * 1000));
        
        // S3에 파일 업로드
        String key = directory + "/" + fileName;
        PutObjectRequest putObjectRequest = new PutObjectRequest(bucket, key, file.getInputStream(), metadata)
            .withCannedAcl(CannedAccessControlList.PublicRead);
        
        amazonS3.putObject(putObjectRequest);
        
        // 업로드된 파일의 URL 반환
        return amazonS3.getUrl(bucket, key).toString();
    }
}
```



## 4. 이미지 처리 파이프라인 구축

이미지 업로드부터 최적화, S3 저장, CDN 배포까지의 전체 과정을 효율적으로 처리하는 파이프라인을 구축합니다.

```java
@Service
@RequiredArgsConstructor
@Slf4j
public class ImageProcessingPipeline {
    
    private final ImageOptimizer imageOptimizer;
    private final S3Service s3Service;
    private final CloudFrontService cloudFrontService;
    private final MemberRepository memberRepository;
    
    /**
     * 이미지 처리 파이프라인 실행
     * @param file 업로드할 이미지 파일
     * @param memberId 사용자 ID
     * @return 처리된 이미지 URL
     * @throws IOException 파일 처리 중 오류 발생 시
     */
    public String processImage(MultipartFile file, Long memberId) throws IOException {
        // 1. 이미지 최적화
        MultipartFile optimizedFile = imageOptimizer.optimizeImage(file);
        
        // 2. S3에 업로드 (캐시 헤더 설정)
        String s3Url = s3Service.uploadFileWithCache(optimizedFile, "profiles");
        
        // 3. CloudFront URL 생성
        String s3Key = s3Service.getS3KeyFromUrl(s3Url);
        String cloudFrontUrl = cloudFrontService.getCloudFrontUrl(s3Key);
        
        // 4. 사용자 정보 업데이트
        Member member = memberRepository.findById(memberId)
            .orElseThrow(() -> new IllegalArgumentException("사용자를 찾을 수 없습니다."));
        
        member.updateProfileImage(cloudFrontUrl, cloudFrontUrl);
        memberRepository.save(member);
        
        return cloudFrontUrl;
    }
}
```


## 5. 오류 처리 및 재시도 메커니즘

네트워크 오류나 일시적인 S3 서비스 중단에 대비하여 재시도 메커니즘을 구현합니다.

```java
@Service
@RequiredArgsConstructor
@Slf4j
public class RetryableS3Service {
    
    private final AmazonS3 amazonS3;
    
    @Value("${cloud.aws.s3.bucket}")
    private String bucket;
    
    private static final int MAX_RETRIES = 3;
    private static final long RETRY_DELAY_MS = 1000;
    
    /**
     * 재시도 가능한 파일 업로드
     * @param file 업로드할 파일
     * @param directory 저장할 디렉토리
     * @return 업로드된 파일의 URL
     * @throws IOException 파일 처리 중 오류 발생 시
     */
    public String uploadFileWithRetry(MultipartFile file, String directory) throws IOException {
        int retryCount = 0;
        Exception lastException = null;
        
        while (retryCount < MAX_RETRIES) {
            try {
                return uploadFile(file, directory);
            } catch (AmazonServiceException e) {
                lastException = e;
                log.warn("S3 업로드 실패 (시도 {}/{}): {}", retryCount + 1, MAX_RETRIES, e.getMessage());
                
                // 재시도 전 대기
                try {
                    Thread.sleep(RETRY_DELAY_MS * (retryCount + 1));
                } catch (InterruptedException ie) {
                    Thread.currentThread().interrupt();
                    throw new IOException("업로드 중단됨", ie);
                }
                
                retryCount++;
            }
        }
        
        throw new IOException("최대 재시도 횟수 초과", lastException);
    }
    
    /**
     * 파일 업로드
     * @param file 업로드할 파일
     * @param directory 저장할 디렉토리
     * @return 업로드된 파일의 URL
     * @throws IOException 파일 처리 중 오류 발생 시
     */
    private String uploadFile(MultipartFile file, String directory) throws IOException {
        // 기존 업로드 로직...
        return "업로드된 파일 URL";
    }
}
```





### (참고 - 클라이언트에서의 방법) Presigned URL을 활용한 직접 업로드

이상 서버에서 이미지 업로드를 효율적으로 하는 방법을 소개했지만, 클라이언트에서도 이미지를 효율적으로 업로드하는 방법이 있습니다. 바로 Presigned URL을 활용하는 것입니다.

Presigned URL은 S3 버킷에 파일을 업로드할 수 있는 임시 URL입니다. 이 URL을 사용하면 클라이언트가 서버를 거치지 않고 직접 S3에 파일을 업로드할 수 있습니다.

작동 방식은 다음과 같습니다:

1. 클라이언트가 서버에 Presigned URL을 요청합니다.
2. 서버는 S3에서 임시 URL을 생성하여 클라이언트에게 전달합니다. (이 임시 URL 은 만료기한을 정할 수 있고, 만료기한 후에 무효화됩니다.)
3. 클라이언트는 받은 URL을 통해 직접 S3에 파일을 업로드합니다.

이 방식의 장점은 다음과 같습니다:
- 서버의 부하가 줄어듭니다
- 업로드 속도가 향상됩니다
- 서버의 대역폭을 절약할 수 있습니다

이러한 다양한 최적화 전략들을 적절히 조합하여 사용하면, 효율적이고 안정적인 이미지 업로드 시스템을 구축할 수 있습니다.

